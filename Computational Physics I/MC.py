import numpy as np
import matplotlib.pyplot as plt
from math import *

def expo(x):
    result=np.exp(-2*x)
    return result

def monte_carlo_sampling(f,nmc,ns,b,a):#nmc (number of monte carlo) is the number of the random numbers generated by the monte carlo method
    #ns (number of sample) is the number of samples we want in this function, f value is the functions we want to integrate, b is as upper bound, a is as lower bound
    
    result=[]#this the list of the result of estimations
    result_3 = [] #this the list of the result of estimations Repeat
    result_3_b = []
    result_5 = []
    result_tot = [] # Ptot values

    for i in range(ns):#this loop is turning the number of the estimates we want
        random_numbers=[]#this is the random numbers generated in that list in every estimate
        for j in range(nmc):#this loop is generating unifrom random numbers
            random_numbers.append(np.random.uniform(a,b))#random number generator

        sample=[]#this is the list that contains the result of function that given input as random numbers
        sample_2=[]

        for k in random_numbers:
            s=f[0]*expo(k)
            sample.append(s)
        I = (b-a)*(1/len(random_numbers))*sum(sample)#this is the integral given in formula
        result.append(I)

        for l in random_numbers:
            z = f[1]*l**2
            sample_2.append(z)
        I_2 = (b-a)*(1/len(random_numbers))*sum(sample_2)#this is the integral given in formula Repeat.
        result_3.append(I_2)

        for d in result_3:
            result_3_b.append(1-d)

    result_2=np.array(result)#making the result list to an array

    result_4=np.array(result_3) #making the result list to an array Repeat
    
    result_5=np.array(result_3_b)

    for u in range(len(result_2)):
        result_tot.append(result[u]+result_3[u])
        type(result_tot)
    result_tot_np = np.array(result_tot)
     
    nu=np.mean(result_tot_np)

    n = result_tot
    l = 1
    for i in range(0,len(n)):
        l*= (np.exp(-k)*(k**result_tot[i]))/(factorial(int(result_tot[i])))
        r= np.log(l)
        return(r)
    lambda2= np.linspace(0.2,1,100)#Lambdas
    likely_hood=[]
    for i in lambda2:
        likely_hood.append(like_hood_calculator(result_tot_np,i))#lambda log likelihood values

    y=list(zip(lk,lambd2))
    q=sorted(y)#find lmax and sort

    Lmin= np.log(np.exp((q[-1][0])-0.5))
    Lmax= np.log(np.exp((q[-1][0])+0.5))
    print("Lmax value and our mean value: ",q[-1])
    print("Upper bound of the error interval: " , Lmax)
    print("Lower bound of the error interval: ", Lmin)

    plt.plot(lambda2,lk,'-r')
    plt.xlabel('lambda')
    plt.ylabel('Log-Likelihood')
    plt.title('Log-Likelihood Plot for Accident result_tot')
    plt.grid(True)


    plt.gcf().savefig("Likelihood graph.pdf")
    

    sigma_2=0 #this is the square of the sigma, same sigma for both.
    
    for t in result_2: #this loop for calculating the sigma
        sigma_2 += (t**2)*(1/ns)*(1/(ns-1))
    
    sigma_2 -= ((sum(result)*(1/ns))**2)*(1/(ns-1)) #The last edit to the sigma val gives the lst form of the sigma which is 0.

    mean_1 = sum(result)/ns #this is the mean of the resulting list
    
    plt.xlabel("Monte-Carlo Estimation of the Integrals")
    plt.ylabel("Value Amounts")
    plt.title("Estimation of Integrals")
    plt.grid(True)
    plt.hist(result_2, bins = 100, alpha = 0.5, label= "First Function")#plotting the estimations
    plt.hist(result_4, bins = 100 ,alpha = 0.5, label= "Second Function")#plotting the estimations Repeat
    plt.legend(loc = 'upper right', ncol=1)
    plt.gcf().savefig("Monte_Carlo_Model.pdf")

    print ((mean_1-np.sqrt(sigma_2)),(mean_1+np.sqrt(sigma_2)),mean_1)
    
    return((mean_1-np.sqrt(sigma_2)),(mean_1+np.sqrt(sigma_2)),mean_1, like_hood_calculator(result_tot, nu))#this gives the mean plus and minus sigma and mean of the estimations


def like_hood_calculator(n,k):#k stands for the mean of the result_tot_np and n for the result_tot
    result_tot = n
    l = 1
    for i in range(0,len(n)):
        l*= (np.exp(-k)*(k**result_tot[i]))/(factorial(int(result_tot[i])))
        r= np.log(l)
        return(r)
    lambda2= np.linspace(0.2,1,100)#Lambdas
    likely_hood=[]
    for i in lambda2:
        likely_hood.append(like_hood_calculator(result_tot_np,i))#lambda log likelihood values

    y=list(zip(lk,lambd2))
    q=sorted(y)#find lmax and sort

    Lmin= np.log(np.exp((q[-1][0])-0.5))
    Lmax= np.log(np.exp((q[-1][0])+0.5))
    print("Lmax value and our mean value: ",q[-1])
    print("Upper bound of the error interval: " , Lmax)
    print("Lower bound of the error interval: ", Lmin)

    plt.plot(lambda2,lk,'-r')
    plt.xlabel('lambda')
    plt.ylabel('Log-Likelihood')
    plt.title('Log-Likelihood Plot for Accident result_tot')
    plt.grid(True)


    plt.gcf().savefig("Likelihood graph.pdf")



ns = int(input("give me a number of sample: "))
nmc = int(input("give me a number of monte carlo random number generated: "))
b = int(input("give me an upper limit: "))
a = int(input("give me a lower limit: "))
f = [] # first give 2.3130352855 then give 2

#I will iterate for 2 plots
for i in range(2):
    pre_f = float(input("give me a value: "))
    f.append(pre_f) # to add element
monte_carlo_sampling(f,nmc,ns,b,a)